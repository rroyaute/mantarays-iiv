[
  {
    "objectID": "outputs/quarto/mantarays-sims.html",
    "href": "outputs/quarto/mantarays-sims.html",
    "title": "Simulations for individual differences in group foraging in manta rays",
    "section": "",
    "text": "0.1 Rationale\nTODO\n\n0.2 Packages Necessary\n\n# Make sure to have these packages installed before runnig the code below\nlibrary(tidyverse);  library(here); library(kableExtra); library(lme4)\nlibrary(brms); library(rptR); library(partR2); library(easystats)\nlibrary(ordinal); library(ggdist); library(tidyverse); library(ggthemes)\nlibrary(patchwork); library(tidybayes); library(visibly)\n\n\n0.3 Simulate variation in leadership preferences\nSetup and individual assignment to foraging groups\nWe imagine a closed population of 100 mantas observed foraging in 100 instances. For simplicity, lets say that mantas always forage in groups of 10 individuals but the identity of each individual present in a given group shifts from observation to observation.\n\nCode# Seed for reproducible simulation\nset.seed(42) \n\n# Value storage\nN_ID = 100\nN_obs = 100\nGroup_size = 10\n# Dataset structure\ndfsim = data.frame(Obs = rep(1:N_obs, each = N_ID),\n                   Id = rep(1:N_ID, N_obs), \n                   # Sample integers from 1 to 10 and repeat 100 times\n                   Group = rep(sample.int(n = Group_size, size = Group_size,\n                                          replace = F), N_obs),\n                   Group_N = 10) %&gt;% \n  mutate(Group_ID = paste(Group, Obs, sep = \"_\"))\ndfsim %&gt;% head(15) %&gt;% kable()\n\n\n\nObs\nId\nGroup\nGroup_N\nGroup_ID\n\n\n\n1\n1\n1\n10\n1_1\n\n\n1\n2\n5\n10\n5_1\n\n\n1\n3\n10\n10\n10_1\n\n\n1\n4\n8\n10\n8_1\n\n\n1\n5\n2\n10\n2_1\n\n\n1\n6\n4\n10\n4_1\n\n\n1\n7\n6\n10\n6_1\n\n\n1\n8\n9\n10\n9_1\n\n\n1\n9\n7\n10\n7_1\n\n\n1\n10\n3\n10\n3_1\n\n\n1\n11\n1\n10\n1_1\n\n\n1\n12\n5\n10\n5_1\n\n\n1\n13\n10\n10\n10_1\n\n\n1\n14\n8\n10\n8_1\n\n\n1\n15\n2\n10\n2_1\n\n\n\n\nCode# Save data \nwrite.csv2(dfsim, here(\"data/data_sim.csv\"))\n\n\nWe now have each individual assigned to a foraging group. We then need to figure out a way to assign ranks corresponding to an individual’s position within the group (1: at the front, 2: second from the front, …).\nIndividual preference for position in group\nThe simplest way to rank individuals is to give them a preference score for belonging to the front or not according to a normal distribution. Here, we assume that this preference is sampled from a normal distribution of mean 0 and a standard deviation of 1 (\\(N(0, 1)\\)). We can store this information in a dataframe format\n\n# Seed for reproducible simulation\nset.seed(42) \n\nID = data.frame(Id = 1:N_ID) %&gt;% \n  mutate(pref = rnorm(n(), 0, 1))\n\nWe then merge the column pref into the dfsim dataframe\n\ndfsim = merge(dfsim, ID)\n\nBased on this preference score, we assign a rank to each individuals within each foraging observation and group. Because the way the rank() function works, individuals with the most negative value are more likely to get a lower rank value.\n\nCodeset.seed(42) \n\ndfsim = dfsim %&gt;% \n  group_by(Group_ID) %&gt;% \n  mutate(rank = rank(pref)) %&gt;% \n  arrange(Obs, Group) %&gt;% \n  ungroup()\ndfsim %&gt;% head(15) %&gt;% kable()\n\n\n\nId\nObs\nGroup\nGroup_N\nGroup_ID\npref\nrank\n\n\n\n1\n1\n1\n10\n1_1\n1.3709584\n8\n\n\n11\n1\n1\n10\n1_1\n1.3048697\n7\n\n\n21\n1\n1\n10\n1_1\n-0.3066386\n3\n\n\n31\n1\n1\n10\n1_1\n0.4554501\n6\n\n\n41\n1\n1\n10\n1_1\n0.2059986\n4\n\n\n51\n1\n1\n10\n1_1\n0.3219253\n5\n\n\n61\n1\n1\n10\n1_1\n-0.3672346\n2\n\n\n71\n1\n1\n10\n1_1\n-1.0431189\n1\n\n\n81\n1\n1\n10\n1_1\n1.5127070\n10\n\n\n91\n1\n1\n10\n1_1\n1.3921164\n9\n\n\n5\n1\n2\n10\n2_1\n0.4042683\n8\n\n\n15\n1\n2\n10\n2_1\n-0.1333213\n6\n\n\n25\n1\n2\n10\n2_1\n1.8951935\n10\n\n\n35\n1\n2\n10\n2_1\n0.5049551\n9\n\n\n45\n1\n2\n10\n2_1\n-1.3682810\n1\n\n\n\n\n\n\n0.4 Data analysis\nI’m comparing 3 GLMM distribution families for analyzing individual position in group: * A binomial GLMM where position is bounded by group size * A Poisson GLMM where position is not bounded by group size * A cumulative link GLMM where ranks are considered discrete ordered categories and are bounded by group size\nThe last model is probably the most accurate but is also the most difficult to work with! By comparing those models, my goal is to figure out if a binomial or Poisson GLMM is sufficient to recover the simulated parameter estimates and to properly predict the distribution of ranks within groups. While calculating repeatability for binomial and Poisson GLMM has been well resolved, there are no known formula for the cumulative link GLMM (that I know of!).\nBinomial GLMM for the probability of leading a foraging groups\n\ndfsim = dfsim %&gt;% \n  mutate(lead = case_when(rank == 1 ~ 1, \n                          rank &gt; 1 ~ 0))\n\nglmm.lead = glmer(lead ~ 1 + (1|Id), \n                  family = \"binomial\", \n                  data = dfsim)\nsummary(glmm.lead)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: lead ~ 1 + (1 | Id)\n   Data: dfsim\n\n     AIC      BIC   logLik deviance df.resid \n    39.5     54.0    -17.8     35.5     9998 \n\nScaled residuals: \n      Min        1Q    Median        3Q       Max \n-0.000053 -0.000053 -0.000053 -0.000053  0.004657 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n Id     (Intercept) 14030    118.4   \nNumber of obs: 10000, groups:  Id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   -19.69       2.41  -8.169 3.11e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCodereport_table(glmm.lead) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nCI\nCI_low\nCI_high\nz\np\nEffects\nGroup\nStd_Coefficient\nStd_Coefficient_CI_low\nStd_Coefficient_CI_high\nFit\n\n\n\n1\n(Intercept)\n-19.6880\n0.95\n-24.41162\n-14.96439\n-8.169119\n0\nfixed\n\n-19.688\n-24.41162\n-14.96439\nNA\n\n\n2\nNA\n118.4474\n0.95\nNA\nNA\nNA\nNA\nrandom\nId\nNA\nNA\nNA\nNA\n\n\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n4\nAIC\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n39.5331704\n\n\n5\nAICc\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n39.5343708\n\n\n6\nBIC\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n53.9538512\n\n\n7\nR2 (conditional)\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.9997656\n\n\n8\nR2 (marginal)\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.0000000\n\n\n11\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.0000000\n\n\n12\nLog_loss\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.0000022\n\n\n\n\nCoder2(glmm.lead) %&gt;% kable()\n\n\n\n\n\n\n\nx\n\n\nConditional R2\n0.9997656\n\n\n\n\n\n\n\nx\n\n\nMarginal R2\n0\n\n\n\n\n\n\nBinomial GLMM for position within foraging groups\n\nglmm.rank.bin = glmer(cbind(rank, Group_N) ~ 1 + (1|Id), \n                      family = \"binomial\", \n                      data = dfsim)\nsummary(glmm.rank.bin)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: cbind(rank, Group_N) ~ 1 + (1 | Id)\n   Data: dfsim\n\n     AIC      BIC   logLik deviance df.resid \n 30416.2  30430.6 -15206.1  30412.2     9998 \n\nScaled residuals: \n      Min        1Q    Median        3Q       Max \n-0.032188 -0.005681  0.002057  0.005625  0.007396 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n Id     (Intercept) 0.4754   0.6895  \nNumber of obs: 10000, groups:  Id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.78954    0.06926   -11.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCodereport_table(glmm.rank.bin) %&gt;% kable()\n\nCan't calculate log-loss.\nCan't calculate proper scoring rules for models without integer response values.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nCI\nCI_low\nCI_high\nz\np\nEffects\nGroup\nStd_Coefficient\nStd_Coefficient_CI_low\nStd_Coefficient_CI_high\nFit\n\n\n\n1\n(Intercept)\n-0.7895394\n0.95\n-0.9252816\n-0.6537971\n-11.40005\n0\nfixed\n\n-0.7895394\n-0.9252816\n-0.6537971\nNA\n\n\n2\nNA\n0.6895083\n0.95\nNA\nNA\nNA\nNA\nrandom\nId\nNA\nNA\nNA\nNA\n\n\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n4\nAIC\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3.041616e+04\n\n\n5\nAICc\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3.041616e+04\n\n\n6\nBIC\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3.043058e+04\n\n\n7\nR2 (conditional)\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.262643e-01\n\n\n8\nR2 (marginal)\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.000000e+00\n\n\n11\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.000000e+00\n\n\n\n\nCodecheck_model(glmm.rank.bin)\n\n\n\n\nPoisson GLMM for position within foraging groups\n\nglmm.rank.poiss = glmer(rank ~ 1 + (1|Id), \n                        family = \"poisson\", \n                        data = dfsim)\nsummary(glmm.rank.poiss)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: rank ~ 1 + (1 | Id)\n   Data: dfsim\n\n     AIC      BIC   logLik deviance df.resid \n 34608.4  34622.8 -17302.2  34604.4     9998 \n\nScaled residuals: \n      Min        1Q    Median        3Q       Max \n-0.030633 -0.004974  0.001646  0.004199  0.005237 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n Id     (Intercept) 0.4764   0.6902  \nNumber of obs: 10000, groups:  Id, 100\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.51255    0.06928   21.83   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCodereport_table(glmm.rank.poiss) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nCI\nCI_low\nCI_high\nz\ndf_error\np\nEffects\nGroup\nStd_Coefficient\nStd_Coefficient_CI_low\nStd_Coefficient_CI_high\nFit\n\n\n\n1\n(Intercept)\n1.5125501\n0.95\n1.376771\n1.648329\n21.83363\nInf\n0\nfixed\n\n1.51255\n1.376771\n1.648329\nNA\n\n\n2\nNA\n0.6902276\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nId\nNA\nNA\nNA\nNA\n\n\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n4\nAIC\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3.460840e+04\n\n\n5\nAICc\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3.460840e+04\n\n\n6\nBIC\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3.462282e+04\n\n\n7\nR2 (conditional)\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7.052244e-01\n\n\n8\nR2 (marginal)\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.000000e+00\n\n\n11\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.000000e+00\n\n\n\n\nCodecheck_model(glmm.rank.poiss)\n\n\n\n\nCumulative Link Mixed Model for position within foraging groups\nWe have two options for CLMMs in R: the ordinal package which fits CLMMs in a frequentist framework and brms which uses a Bayesian approach. I have a strong preference for working with brms given its flexibility and lots of functionality for extracting parameter values and plotting. In contrast, ordinal only handles 1 random effect within a model and several utility functions such as predict() are not implemented yet.\n\ndfsim$rank.f = as.factor(dfsim$rank)\nclmm.rank = clmm(rank.f ~ 1 + (1|Id), data = dfsim, threshold = \"equidistant\")\nclmm.rank\n\nCumulative Link Mixed Model fitted with the Laplace approximation\n\nformula: rank.f ~ 1 + (1 | Id)\ndata:    dfsim\n\n link  threshold   nobs  logLik  AIC    niter      max.grad\n logit equidistant 10000 -220.31 446.63 401(12553) 3.13e+00\n\nRandom effects:\n Groups Name        Variance Std.Dev.\n Id     (Intercept) 14874    122     \nNumber of groups:  Id 100 \n\nNo Coefficients\n\nThresholds:\nthreshold.1     spacing \n     -68.22       26.50 \n\n\n\nbrms.rank = brm(rank ~ 1 + (1|Id), \n                data = dfsim,\n                family = \"cumulative\",\n                cores = 4, \n                threads = 4, \n                iter = 500,\n                seed = 42,\n                backend = \"cmdstanr\", \n                file = here(\"outputs/mods/brms.rank\"))\n\n\nreport_table(brms.rank) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nMedian\nCI\nCI_low\nCI_high\npd\nRhat\nESS\nStd_Median\nStd_Median_CI_low\nStd_Median_CI_high\nFit\n\n\n\n1\nIntercept[1]\n-194.771500\n0.95\n-284.9987000\n-130.7574250\n1.000\n1.058004\n74.93820\n-194.771500\n-284.9987000\n-130.7574250\nNA\n\n\n2\nIntercept[2]\n-121.846500\n0.95\n-184.0386750\n-77.2297625\n1.000\n1.071357\n54.33070\n-121.846500\n-184.0386750\n-77.2297625\nNA\n\n\n3\nIntercept[3]\n-70.389900\n0.95\n-119.9223750\n-33.4036200\n1.000\n1.082688\n46.55981\n-70.389900\n-119.9223750\n-33.4036200\nNA\n\n\n4\nIntercept[4]\n-30.046850\n0.95\n-69.8278100\n0.4246816\n0.967\n1.075347\n37.56906\n-30.046850\n-69.8278100\n0.4246816\nNA\n\n\n5\nIntercept[5]\n0.607018\n0.95\n-30.0850875\n30.0031875\n0.559\n1.087004\n31.68301\n0.607018\n-30.0850875\n30.0031875\nNA\n\n\n6\nIntercept[6]\n34.452750\n0.95\n0.4793536\n70.2040600\n0.981\n1.089448\n35.42682\n34.452750\n0.4793536\n70.2040600\nNA\n\n\n7\nIntercept[7]\n75.545850\n0.95\n37.4468850\n125.7313750\n1.000\n1.059517\n51.64699\n75.545850\n37.4468850\n125.7313750\nNA\n\n\n8\nIntercept[8]\n127.410000\n0.95\n87.5496025\n193.9234500\n1.000\n1.058296\n85.66555\n127.410000\n87.5496025\n193.9234500\nNA\n\n\n9\nIntercept[9]\n201.627000\n0.95\n145.3978750\n310.4558250\n1.000\n1.030180\n141.10004\n201.627000\n145.3978750\n310.4558250\nNA\n\n\n10\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n11\nELPD\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n-5.5245981\n\n\n13\nLOOIC\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n11.0491963\n\n\n15\nWAIC\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n11.0477429\n\n\n16\nR2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.9999995\n\n\n17\nR2 (marginal)\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.0000000\n\n\n19\nSigma\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.0000000\n\n\n\n\npp_check(brms.rank, ndraws = 100)\n\n\n\n\n\n0.5 Comparing the predictive accuracy of the models\nWe can fit all these models as Bayesian models and compare posterior predictive checks to compare whether one model predicts the data more accurately. We first need to define some reasonable priors and explore prior predictive checks (i.e. how the model might predict data points without having seen the data yet, taking information only from the priors).\n\nbf.bin = bf(rank | trials(Group_N) ~ 1 + (1|Id),\n            family = \"binomial\")\n\nbf.poiss = bf(rank ~ 1 + (1|Id),\n              family = \"poisson\")\n\nbf.clmm = bf(rank ~ 1 + (1|Id),\n             family = \"cumulative\")\n\npriors.bin &lt;- \n  # Intercepts priors\n  prior(normal(.2, .05), class = Intercept) +\n  # Random effects priors (default to exp(1))\n  prior(exponential(1), class = sd)\n\npriors.poiss &lt;- \n  # Intercepts priors\n  prior(normal(1.6, .1), class = Intercept, lb = 0) +\n  # Random effects priors\n  prior(exponential(1), class = sd)\n\npriors.clmm &lt;- \n  # Intercepts priors (default to exp(1))\n  prior(normal(0, 1), class = Intercept) +\n  # Random effects priors (default to exp(1))\n  prior(exponential(1), class = sd)\n\nWithout getting too much into the details, I’m choosing priors based on the expected average position in a group of 10 individuals. With the binomial GLMM, this translate into the probability of occupying a rank between 1 and 10 in a group of 10 = 0.55. This corresponds to an intercept value of 0.2 on the logit scale. Similarly, the mean position in a group of 10 individual is 5.5, which correspond to an intercept of 1.5 on the exponential scale.\nWe then apply these priors to the simulated data structure\n\nbrms.bin.prior = brm(bf.bin,\n                     data = dfsim,\n                     prior = priors.bin,\n                     sample_prior = \"only\",\n                     warmup = 1000,\n                     iter = 2000,\n                     seed = 42, \n                     cores = 8, \n                     threads = threading(8),\n                     control = list(adapt_delta = .99,\n                                    max_treedepth = 15),\n                     backend = \"cmdstanr\", \n                     file_refit = \"always\",\n                     file = here(\"outputs/mods/brms.bin.prior\"))\n\nbrms.poiss.prior = brm(bf.poiss, \n                       data = dfsim,\n                       prior = priors.poiss,\n                       sample_prior = \"only\",\n                       warmup = 1000,\n                       iter = 2000,\n                       seed = 42, \n                       cores = 8, \n                       threads = threading(8),\n                       control = list(adapt_delta = .99,\n                                      max_treedepth = 15),\n                       backend = \"cmdstanr\", \n                       file_refit = \"always\",\n                       file = here(\"outputs/mods/brms.poiss.prior\"))\n\nbrms.clmm.prior = brm(bf.clmm, \n                      data = dfsim,\n                      prior = priors.clmm,\n                      sample_prior = \"only\",\n                      warmup = 1000,\n                      iter = 2000,\n                      seed = 42, \n                      cores = 8,\n                      threads = threading(8),\n                      control = list(adapt_delta = .99,\n                                     max_treedepth = 15),\n                      backend = \"cmdstanr\", \n                      file_refit = \"always\",\n                      file = here(\"outputs/mods/brms.clmm.prior\"))\n\nAnd next plot draws from the prior distribution\n\nplot.bin = pp_check(brms.bin.prior, ndraws = 500) +\n  xlim(0, 15) +\n  ggtitle(\"Binomial GLMM\") \n\nplot.poiss = pp_check(brms.poiss.prior, ndraws = 500) +\n  xlim(0, 15) +\n  ggtitle(\"Poisson GLMM\") \n\nplot.clmm = pp_check(brms.clmm.prior, ndraws = 500) +\n  xlim(0, 15) +\n  ggtitle(\"Cumulative Link Mixed Model\")\n\nplot.priorpcheck = (plot.bin / plot.poiss / plot.clmm) +\n  plot_annotation(\"Prior-predictive checks\") &\n  theme_bw(14)\nplot.priorpcheck\n\n\n\nFigure 1: Prior predictive checks for the distribution of individual positions within manta foraging groups\n\n\n\nWe can already spot some potential issues! Both binomial and Poisson GLMMs predict ranks of 0, which is impossible given our data structure. The cumulative link mixed model seems to fit the data more correctly instead.\nUsing the same priors, we now fit these models to the simulated data\n\nbrms.bin = brm(bf.bin,\n                     data = dfsim,\n                     prior = priors.bin,\n                     warmup = 5000,\n                     iter = 6000,\n                     seed = 42, \n                     cores = 8, \n                     threads = threading(8),\n                     control = list(adapt_delta = .99,\n                                    max_treedepth = 15),\n                     backend = \"cmdstanr\", \n                     file_refit = \"always\",\n                     file = here(\"outputs/mods/brms.bin\"))\n\nbrms.poiss = brm(bf.poiss, \n                       data = dfsim,\n                       prior = priors.poiss,\n                       warmup = 5000,\n                       iter = 6000,\n                       seed = 42, \n                       cores = 8, \n                       threads = threading(8),\n                       control = list(adapt_delta = .99,\n                                      max_treedepth = 15),\n                       backend = \"cmdstanr\", \n                       file_refit = \"always\",\n                       file = here(\"outputs/mods/brms.poiss\"))\n\nbrms.clmm = brm(bf.clmm, \n                      data = dfsim,\n                      prior = priors.clmm,\n                      warmup = 5000,\n                      iter = 6000,\n                      seed = 42, \n                      cores = 8,\n                      threads = threading(8),\n                      control = list(adapt_delta = .99,\n                                     max_treedepth = 15),\n                      backend = \"cmdstanr\", \n                      file_refit = \"always\",\n                      file = here(\"outputs/mods/brms.clmm\"))\n\nAnd compare predictive checks based on draws from the posterior distribution\n\nplot.bin = pp_check(brms.bin, ndraws = 500) +\n  xlim(0, 10) +\n  ggtitle(\"Binomial GLMM\") \n\nplot.poiss = pp_check(brms.poiss, ndraws = 500) +\n  xlim(0, 10) +\n  ggtitle(\"Poisson GLMM\") \n\nplot.clmm = pp_check(brms.clmm, ndraws = 500) +\n  xlim(0, 10) +\n  ggtitle(\"Cumulative Link Mixed Model\")\n\n\nplot.ppcheck = (plot.bin / plot.poiss / plot.clmm) +\n  plot_annotation(\"Posterior-predictive checks\") &\n  theme_bw(14)\nplot.ppcheck\n\n\n\nFigure 2: Posterior predictive checks for the distribution of individual positions within manta foraging groups\n\n\n\nThe issues noted above persist with the simulated data. We now to figure out how much of an issue this discrepancy might be in the context of estimating individual differences in individual position within foraging groups. There are also a number of convergence issues with the binomial and Poisson approaches that we don’t encounter with the CLMM model (see R\\test.brms.R file for the full report) .\nEstimation of among-individual variance\n\nVi.bin = brms.bin %&gt;% \n  spread_draws(sd_Id__Intercept)\n\nVi.poiss = brms.poiss %&gt;% \n  spread_draws(sd_Id__Intercept)\n\nVi.clmm = brms.clmm %&gt;% \n  spread_draws(sd_Id__Intercept)\n\ndf.Vi = data.frame(\n  Vi = c(Vi.bin$sd_Id__Intercept,\n         Vi.poiss$sd_Id__Intercept,\n         Vi.clmm$sd_Id__Intercept),\n  Mod = factor(c(rep(\"Binomial\", length(Vi.bin$sd_Id__Intercept)),\n                    rep(\"Poisson\", length(Vi.poiss$sd_Id__Intercept)),\n                 rep(\"CLMM\", length(Vi.clmm$sd_Id__Intercept))),\n                  levels = c(\"Binomial\", \"Poisson\", \"CLMM\")))\n\nplot.Vi = df.Vi %&gt;% \n  ggplot(aes(x = Vi, y = Mod, fill = Mod)) +\n  stat_halfeye() + \n  scale_fill_wsj() +\n  xlab(\"Among-individual variance\") +\n  ylab(\"Model\") +\n  theme_bw(14) +\n  theme(legend.position = \"none\")\nplot.Vi\n\n\n\nFigure 3: Among-individual variance estimates compared among three types of GLMMs for individual position in foraging groups\n\n\n\nAs we can see, the variances have little in common between the three models. An added difficulty is that have a firm grasp on what the simulated variance ought to be. Individuals were given a value sampled from a \\(Normal(0, 1)\\) distribution but were then ranked at each observation. We can calculate the variance for mean individual rank as a proxy for the true among-individual variance though\n\ndfsim %&gt;% \n  group_by(Id, Obs) %&gt;% \n  mutate(mean_rank = mean(rank)) %&gt;% \n  ungroup() %&gt;% \n  summarise(Vi = var(mean_rank))\n\n# A tibble: 1 × 1\n     Vi\n  &lt;dbl&gt;\n1  8.25\n\n\nWe may also ask how accurate the random effect values for each individual are compared to our simulation.\n\np1 = plot_coefficients(brms.bin, ranef = TRUE, which_ranef = \"Id\")\np2 = plot_coefficients(brms.poiss, ranef = TRUE, which_ranef = \"Id\")\np3 = plot_coefficients(brms.poiss, ranef = TRUE, which_ranef = \"Id\")\n\n(p1 + p2 + p3 ) & theme_bw(14)\n\n\n\nFigure 4: Random effect values compared among three types of GLMMs\n\n\n\nAs we can see, the random effects are expressed on very different scales, making comparisons difficult!\n\n0.6 Conclusions on best models for position within group\nThere is a clear advantage for the CLMM model which performs much better than the binomial or Poisson GLMMs. However, estimating the repeatability for this class of model remains tricky! With non-Gaussian GLMMs, the residual variance is not a statistical parameter estimated from the model, but rather depends on the link function used and the overdispersion type used to fit the model. These issues are now well-resolved for binomial, Poisson and Gamma distribution. However, there is no guidance, to my knowledge, in how to calculate the residual variance with CLMMs. Given these limitations, it seems much more appropriate to compare variability among and within individuals using the leading/following data rather than relying on an individual’s exact position within the group. This should give qualitatively equivalent data on whether some individuals are more likely to position themselves at the front of the foraging chain and therefore seems the much wiser option!\n\n0.7 Comparing repeatability and variance components between groups\nI focus here in the leading/following behaviors as they are much more consistent with a binomial GLMM. For convenience, I simply allocated individuals to male or female categories at random and do not assume any differences among sexes.\n\n# Make a fake sex column where half individuals get assigned as females and the other half as males\nID$Sex &lt;- as.factor(c(rep(\"F\", nrow(ID)/2),\n                      rep(\"M\", nrow(ID)/2)))\ndfsim = merge(dfsim, ID)\n\nAs in section 1\nEstimate repeatability by sex\n\nrpt.R.f = rpt(formula = lead ~ 1 + (1|Id), \n            grname = \"Id\", \n            datatype = \"Binary\", \n            data = subset(dfsim, Sex == \"F\"))\nrpt.R.m = rpt(formula = lead ~ 1 + (1|Id), \n            grname = \"Id\", \n            datatype = \"Binary\", \n            data = subset(dfsim, Sex == \"M\"))\nsaveRDS(rpt.R.f, here(\"outputs/mods/rpt.R.f.rds\"))\nsaveRDS(rpt.R.m, here(\"outputs/mods/rpt.R.m.rds\"))\n\nThis code store the values for repeatability into an rpt object. We can access the numeric values of each bootstrap from within the R_boot column and plot the distribution or the distribution for the difference between each sexes.\n\n\n\n\n\n\nNote\n\n\n\nFor convenience, I’m calculating an ‘adjusted repeatability’, which correspond to \\(R_{adj} = \\frac{V_i}{V_i + V_r}\\), where \\(V_i\\) is the among-individual variance and \\(V_r\\) is the residual variance (a.k.a. the the within-individual variance). In other terms, I’m ‘adjusting’ the repeatability value by leaving out the variance explained by fixed effects from the denominator. We could also consider that sexes contribute to the variation in leading or following during foraging event. In which case, we would compute the ‘unadjusted repeatability’ by including the fixed effect variance (\\(V_{fe}\\)) in the denominator: \\(R_{unadj} = \\frac{V_i}{V_i + V_{fe} + V_r}\\). This is easily done by setting the adjusted argument to adjusted = T within the rptr() function.\n\n\n\n# Inspect rpt objects\nsummary(rpt.R.f)\n\n\nRepeatability estimation using glmer method\n\nCall = rpt(formula = lead ~ 1 + (1 | Id), grname = \"Id\", data = subset(dfsim, Sex == \"F\"), datatype = \"Binary\")\n\nData: 5000 observations\n----------------------------------------\n\nId (50 groups)\n\nRepeatability estimation overview: \n          R       SE   2.5%  97.5% P_permut\nOrg   0.809 5.83e+02  0.259   2543       NA\nLink  0.999 1.19e-03  0.997      1       NA\n\n\nBootstrapping: \n          N    Mean Median   2.5%  97.5%\nOrg    1000 229.197  0.360  0.259   2543\nLink   1000   0.999  0.999  0.997      1\n\nPermutation test: \n          N   Mean Median   2.5%  97.5% P_permut\nOrg       1     NA     NA     NA     NA       NA\nLink      1     NA     NA     NA     NA       NA\n\nLikelihood ratio test: \nlogLik full model = -8.883293\nlogLik red. model = -1625.415\nD  = 3230, df = 1, P = 0\n\n----------------------------------------\n\nsummary(rpt.R.m)\n\n\nRepeatability estimation using glmer method\n\nCall = rpt(formula = lead ~ 1 + (1 | Id), grname = \"Id\", data = subset(dfsim, Sex == \"M\"), datatype = \"Binary\")\n\nData: 5000 observations\n----------------------------------------\n\nId (50 groups)\n\nRepeatability estimation overview: \n          R       SE   2.5%  97.5% P_permut\nOrg   0.809 5.53e+02  0.258   2542       NA\nLink  0.999 1.11e-03  0.997      1       NA\n\n\nBootstrapping: \n          N    Mean Median   2.5%  97.5%\nOrg    1000 216.128  0.359  0.258   2542\nLink   1000   0.999  0.999  0.997      1\n\nPermutation test: \n          N   Mean Median   2.5%  97.5% P_permut\nOrg       1     NA     NA     NA     NA       NA\nLink      1     NA     NA     NA     NA       NA\n\nLikelihood ratio test: \nlogLik full model = -8.883293\nlogLik red. model = -1625.415\nD  = 3230, df = 1, P = 0\n\n----------------------------------------\n\n\nEstimate among and within-individual variance by sex\nTo get the among and within-individual variances, we need to rerun the rpt function, this time specifying that we want to extract the variance rather than the repeatablities. This can be done by setting the ratio argument to ratio = F\n\nrpt.V.f &lt;- rpt(formula = lead ~ 1 + (1|Id), \n               grname = c(\"Id\", \"Fixed\", \"Residual\"), \n               datatype = c(\"Binary\"), \n               data = subset(dfsim, Sex == \"F\"),\n               ratio = FALSE)\nrpt.V.m &lt;- rpt(formula = lead ~ 1 + (1|Id), \n               grname = c(\"Id\", \"Fixed\", \"Residual\"), \n               datatype = \"Binary\", \n               data = subset(dfsim, Sex == \"M\"),\n               ratio = FALSE)\n\nsaveRDS(rpt.V.f, here(\"outputs/mods/rpt.V.f.rds\"))\nsaveRDS(rpt.V.m, here(\"outputs/mods/rpt.V.m.rds\"))\n\nCombining all elements into a nice plot\n\n# Store all vectors of bootstrapped values\nVi_f &lt;- rpt.V.f$R_boot_link$Id\nVi_m &lt;- rpt.V.m$R_boot_link$Id\nVfe_f &lt;- rpt.V.f$R_boot_link$Fixed\nVfe_m &lt;- rpt.V.m$R_boot_link$Fixed\nVR_f &lt;- rpt.V.f$R_boot_link$Residual\nVR_m &lt;- rpt.V.m$R_boot_link$Residual\nR_f &lt;- rpt.R.f$R_boot_link$Id\nR_m &lt;- rpt.R.m$R_boot_link$Id\n\ndf &lt;- data.frame(Vi = c(Vi_f, Vi_m),\n                 Vfe = c(Vfe_f, Vfe_m),\n                 VR = c(VR_f, VR_m),\n                 R = c(R_f, R_m),\n                 Sex = c(rep(\"F\", length(Vi_f)),\n                         rep(\"M\", length(Vi_m))))\n# Store effect sizes\ndf.2  &lt;- data.frame(delta_Vi = Vi_f - Vi_m,\n                    delta_Vfe = Vfe_f - Vfe_m,\n                    delta_VR = VR_f - VR_m,\n                    delta_R = R_f - R_m)\n\n\np1 = df %&gt;% \n  ggplot(aes(x = Vi, fill = Sex)) +\n  stat_halfeye(alpha = .6) + \n  scale_fill_wsj() +\n  xlab(bquote(\"Among-individual variance (\"*V[i]*\")\")) +\n  ylab(\"Density\") +\n  theme_bw(14)\ndelta.p1 = df.2 %&gt;% \n  ggplot(aes(x = delta_Vi)) +\n  stat_halfeye(alpha = .6) + \n  xlab(bquote(Delta[V[i]])) +\n  ylab(\"Density\") +\n  theme_bw(14)\np1 = p1 + delta.p1\n\np2 = df %&gt;% \n  ggplot(aes(x = Vfe, fill = Sex)) +\n  stat_halfeye(alpha = .6) + \n  scale_fill_wsj() +\n  xlab(bquote(\"Fixed effect variance (\"*V[fe]*\")\")) +\n  ylab(\"Density\") +\n  theme_bw(14)\ndelta.p2 = df.2 %&gt;% \n  ggplot(aes(x = delta_Vfe)) +\n  stat_halfeye(alpha = .6) + \n  xlab(bquote(Delta[V[fe]])) +\n  ylab(\"Density\") +\n  theme_bw(14)\np2 = p2 + delta.p2\n\n\np3 = df %&gt;% \n  ggplot(aes(x = Vfe, fill = Sex)) +\n  stat_halfeye(alpha = .6) + \n  scale_fill_wsj() +\n  xlab(bquote(\"Residual variance (\"*V[R]*\")\")) +\n  ylab(\"Density\") +\n  theme_bw(14)\ndelta.p3 = df.2 %&gt;% \n  ggplot(aes(x = delta_VR)) +\n  stat_halfeye(alpha = .6) + \n  xlab(bquote(Delta[V[fe]])) +\n  ylab(\"Density\") +\n  theme_bw(14)\np3 = p3 + delta.p3\n\np4 = df %&gt;% \n  ggplot(aes(x = R, fill = Sex)) +\n  stat_halfeye(alpha = .6) + \n  scale_fill_wsj() +\n  xlim(0, 1) +\n  xlab(bquote(\"Repeatability (R)\")) +\n  ylab(\"Density\") +\n  theme_bw(14)\ndelta.p4 = df.2 %&gt;% \n  ggplot(aes(x = delta_R)) +\n  stat_halfeye(alpha = .6) + \n  xlim(0, 1) +\n  xlab(bquote(Delta[R])) +\n  ylab(\"Density\") +\n  theme_bw(14)\np4 = p4 + delta.p4\n\nplot_var_R = p1 / p2 / p3 / p4\nplot_var_R\n\n\n\nFigure 5: Variance components and difference in variances compared among sexes\n\n\n\nThe output looks a little janky, but that’s not surprising given that we’ve simulated data with no fixed effects. In our case, the only source of variation comes from the amon-individual preferences for being at the front or the back of the group. Hence, the variation explained by fixed effects and residuals reduces to 0 and repeatability equals 1 in our case."
  }
]